name: Hourly Scrape and Daily Batch Jobs

on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    # Runs near the beginning of every hour (e.g., 5 mins past)
    - cron: '5 * * * *'
permissions:
  contents: write

jobs:
  # Job 1: Scrape data and commit the result JSON
  scrape-and-commit:
    runs-on: ubuntu-latest
    outputs:
      # Output whether the scraper successfully committed new data
      data_updated: ${{ steps.commit_data.outputs.committed }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4 # Use latest version

      - name: Set up Python 3.9
        uses: actions/setup-python@v5 # Use latest version
        with:
          python-version: '3.9'

      - name: Install Scraper Dependencies
        run: |
          python -m pip install --upgrade pip
          # Dependencies needed for cpcb_scraper.py
          pip install pandas requests numpy

      - name: Create output directory for scraped data
        # Ensure the target directory exists before running the scraper
        run: mkdir -p backend/static/scraped_data

      - name: Run CPCB Scraper
        # Assumes cpcb_scraper.py is in the project root
        run: python cpcb_scraper.py

      - name: Commit Scraped Data File
        id: commit_data # Give step an ID to reference its output
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          # Specifically add the JSON file generated by the scraper
          git add backend/static/scraped_data/latest_cpcb_data.json
          # Check if the file changed and set the output variable accordingly
          if git diff --staged --quiet; then
            echo "No changes detected in scraped data file."
            echo "committed=false" >> $GITHUB_OUTPUT
          else
            echo "Changes detected. Committing scraped data file..."
            git commit -m "Update CPCB water quality data"
            echo "committed=true" >> $GITHUB_OUTPUT
          fi
          # Attempt to push changes (will only push if a commit was made)
          git push

  # Job 2: Update database hourly and run batch jobs daily
  update-db-and-run-jobs:
    runs-on: ubuntu-latest
    # This job depends on the successful completion of the scrape job
    needs: scrape-and-commit

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        # Fetch full history - might be needed if batch jobs analyze trends
        with:
          fetch-depth: 0

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Install Full Dependencies
        run: |
          python -m pip install --upgrade pip
          # Install all packages needed by update_pipeline.py AND run_all_batch_jobs.py
          # Adjust this list based on your actual project requirements!
          pip install pandas requests numpy tensorflow scikit-learn plotly joblib apscheduler Flask Flask-Cors

      - name: Run Database Update Pipeline
        # Run the script located in the backend directory
        run: python backend/update_pipeline.py

      # --- Daily Batch Job Execution ---
      # Runs only once a day, around 00:05 UTC. Adjust cron time as needed.
      # Uses github.run_attempt to avoid re-running on workflow retries within the same hour.
      - name: Run All Batch Jobs (Daily ~00:05 UTC)
        # Check if it's the first attempt for this run AND if the schedule matches the daily run time
        if: github.run_attempt == '1' && startsWith(github.event.schedule, '5 0 * * *')
        run: |
          echo "Running daily batch jobs..."
          # Run the script located in the backend directory
          python backend/run_all_batch_jobs.py

      - name: Commit Generated Plot Files (Daily)
        # Run only if the daily batch jobs step likely ran (matches the 'if' condition above)
        if: github.run_attempt == '1' && startsWith(github.event.schedule, '5 0 * * *')
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          echo "Checking for changes in generated files..."
          # Add all potentially generated/updated files from batch jobs
          git add backend/static/predictions/daily/*.json
          git add backend/static/predictions/weekly/*.json
          git add backend/static/predictions/weekly_details/*.json
          git add backend/static/predictions/*.json # Summary files
          git add backend/static/correlation/*.json
          git add backend/static/anomaly/*.json
          git add backend/static/daynight/*.png
          # Check if any added files actually have changes
          if git diff --staged --quiet; then
            echo "No changes detected in generated plot/summary files."
          else
            echo "Changes detected. Committing generated files..."
            git commit -m "Update generated analysis plots and summaries"
            git push
          fi